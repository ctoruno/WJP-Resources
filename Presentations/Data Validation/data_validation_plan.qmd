---
title: "Data Validation Plan"
format:
  revealjs: 
    theme: [simple, custom.scss]
    embed-resources: true
editor: visual
---

## {.smaller}

### Quantitative Data Validation {.smaller}

-   **GPP data: Country data validation and outcomes validaton**

-   QRQ data validation

### Qualitative Checks

-   Traditional qualitative cross-checks

-   **Massive analysis using AI**

-   Interviews with experts

# GPP Quantitative Validation

## Quantitative Validation {.smaller}

- Country data validation: Pretest

    - The pretest process occurs before the pooling companies start the collection of data. This aims to evaluate that all the material for the full fieldwork is correct

- Country data validation: Full fieldwork

    - After receiving data from pooling companies, we verify representativeness and alignment with each country's patterns, warnings cannot be returned with pooling companies.

- Outcomes Validation

    - The final stage in our data verification process involves validating the estimated outcomes constructed with our dataset.

## Country data validation  {.smaller}

::: {.panel-tabset}

## Sample Representativeness

- Sample distributions

    - By sociodemographic group
    - By NUTS and country level


- Missing values
- Difficulty score (Face-to-Face only)
    
## Patterns and Correspondence

- Internal checks (key variables)
    - Overtime changes (t-test)
    - Subnational rankings*
- External checks (Multilevel analysis)
    - Aggregated scores analysis (level 1)
    - Question level analysis (level 2)
    - Extreme outlier detection (level 3)
    
:::
## Country data validation: Pretest {.smaller}

- Deliverable: A report document along with a supplementary Excel file for each country

![](media/pretest.jpeg)


## Country data validation: Full fieldwork {.smaller}

- Deliverable: Internal report or platform summarizing flags and issues at the country level

![](media/fullfieldwork.jpeg)



## Outcomes Validation {.smaller}

- Internal checks

    - Aggregated variables at the sub-national level and detect outliers among all 110 NUTS regions.

- External checks

    - Ranking comparisons validation between key variables from the GPP and selected TPS indicators

## Deliverables Desing {.smaller}

- Pretest data

    - A document highlighting the potential problematic variables

- Full fieldwork data
    
    - An HTML country report that will contain all the flags finding in the proposed analysis
    - Attach to the HTML will be included a complementary excel with all the analysis

- Outcomes Validation

    - The HTML serves as a complement to those generated following the full fieldwork collection
    - The HTML will primarily focus on presenting the results and highlighting problematic data points

# Task and Current Status {.smaller}

## Tasks {.smaller}

::: {.panel-tabset}

## Variables selection

**Responsible:** Horacio and Gustavo \
**Support:** Data Analytics

- TPS selection (90%)
- Quasi-comparables matches (TPS-GPP) identification (80%)
- TPS recollection, data and cleaning (90%)

## Validation coding

**Responsible:** Data Analytics \
**Support:** Natalia Rodriguez

- Country data validation programming (30%)
- Outcomes validation programming (0%)

## Deliverables design

**Responsible:** Data Analytics

- Design of reports and excels for Pretest (30%)
- Platform design and creation (0%)

:::

## QRQ data validation {.smaller}

- Similar to the validation process carried out by the Index Team
- Focused on flagging individuals (outliers)
- Sensitivity analysis

    - How much do the scores change by dropping individuals/questions?
    
- Deliverable: an excel file similar to the map file used by the index team

# Massive analysis using AI: Overview

## Developing a news articles gathering and classification system {.smaller}

- Data collection trough a news data API

    - Access to a massive news data archive (1.000.000 articles per month)
    - Filter data by topic, newspaper and date

- Data labeling

    - WebApp to help team labeling data
    
- Model training

    - Machine Learning and Neural Networks (drip modelling)
    - AWS cloud computing (depends of the model)
    
- Model deployment (TBD)

## Implementing extensions (analysis) {.smaller}


- Topic Modeling Analysis

    - Identify number of topics, along with keywords and events for each one of them
    
- Summary of events

    - Automatic summaries of clustered news data
    
- Country/regional report
    
    - Summary of main news articles and events highligting key topic.
  


